{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class DataValidationArtifact:\n",
    "    valid_train_path: Path\n",
    "    valid_test_path: Path\n",
    "    invalid_train_path: Path\n",
    "    invalid_test_path: Path\n",
    "    validation_status: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Data Science\\\\github\\\\Projects\\\\ML\\\\Credit-Card-Transaction-Fraud-Detection\\\\Notebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"d:\\\\Data Science\\\\github\\\\Projects\\\\ML\\\\Credit-Card-Transaction-Fraud-Detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "class TrainingPipeline:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.artifact = os.path.join(\"artifacts\")\n",
    "\n",
    "\n",
    "class DataValidationConfig:\n",
    "    def __init__(self, training_pipeline: TrainingPipeline):\n",
    "        \n",
    "        data_validation_dir = os.path.join(training_pipeline.artifact, \"data validation\")\n",
    "        self.validation_train_path = os.path.join(data_validation_dir, \"valid\", \"train.csv\")\n",
    "        self.valid_test_path = os.path.join(data_validation_dir, \"valid\", \"test.csv\")\n",
    "        self.invalid_train_path = os.path.join(data_validation_dir, \"invalid\", \"train.csv\")\n",
    "        self.invalid_test_path = os.path.join(data_validation_dir, \"valid\", \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "from sklearn.model_selection import train_test_split\n",
    "class DataValidation:\n",
    "\n",
    "    def __init__(self, data_validation_config: DataValidationConfig):\n",
    "        self.data_validation_config = data_validation_config\n",
    "        self.numeric_columns = ['cc_num', 'amt', 'zip', 'lat', 'long', 'city_pop', \n",
    "                                'unix_time',\n",
    "                                'merch_lat', 'merch_long', 'is_fraud']\n",
    "        \n",
    "        self.cat_columns = ['trans_date_trans_time','merchant', 'category', \n",
    "                            'first', 'last', 'gender', \n",
    "                            'street', 'city',\n",
    "                            'state', 'job', 'dob', 'trans_num']\n",
    "\n",
    "\n",
    "    def numerical_exists(self, df:pd.DataFrame) -> bool:\n",
    "\n",
    "        expected_columns = df.select_dtypes(exclude='object')\n",
    "\n",
    "        if len(self.numeric_columns) == expected_columns.shape[1]:\n",
    "            for i in range(len(self.numeric_columns)):\n",
    "                if self.numeric_columns[i] in expected_columns:\n",
    "                    return True\n",
    "            else:\n",
    "                raise Exception(f\"the column {self.numeric_columns[i]} is not found in the dataset\")\n",
    "        else:              \n",
    "            raise Exception(f\"the number of expected columns is not equal to no. of required columns\")\n",
    "\n",
    "    \n",
    "    def categorical_exits(self, df:pd.DataFrame):\n",
    "\n",
    "        expected_columns = df.select_dtypes(include='object')\n",
    "\n",
    "        if len(self.cat_columns) == expected_columns.shape[1]:\n",
    "            for i in range(len(self.cat_columns)):\n",
    "                print(self.cat_columns[i])\n",
    "                if self.cat_columns[i] in expected_columns:\n",
    "                    return True\n",
    "            else:\n",
    "                raise Exception(f\"the column {self.cat_columns[i]} is not found in the dataset\")\n",
    "        else:              \n",
    "            raise Exception(f\"the number of expected columns is not equal to no. of required columns\")\n",
    "\n",
    "    def drift(self, base_df:pd.DataFrame, current_df:pd.DataFrame, threshold=0.05):\n",
    "        report = {}\n",
    "        status = True\n",
    "\n",
    "        for column in base_df.columns:\n",
    "            d1 = base_df[column]\n",
    "            d2 = current_df[column]\n",
    "\n",
    "            is_same_dist = ks_2samp(d1, d2)\n",
    "\n",
    "            if threshold<=is_same_dist.pvalue:\n",
    "                is_found=False\n",
    "            else:\n",
    "                is_found=True\n",
    "                status=False\n",
    "            report.update({column:{\n",
    "                \"p_value\":float(is_same_dist.pvalue),\n",
    "                \"drift_status\":is_found\n",
    "                \n",
    "                }})\n",
    "\n",
    "        return report\n",
    "        \n",
    "    def initiate_data_validation(self):\n",
    "\n",
    "        df = pd.read_csv(\"./dataset/CreditCardData.csv\")\n",
    "\n",
    "        train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "        train_data.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
    "        test_data.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "        status = self.numerical_exists(train_data)\n",
    "        if status:\n",
    "            print(\"the numerical columns exists for train data\")\n",
    "\n",
    "        status = self.numerical_exists(test_data)\n",
    "        if status:\n",
    "            print(\"the numerical columns exists for test data\")\n",
    "\n",
    "        status = self.categorical_exits(train_data)\n",
    "        if status:\n",
    "            print(\"the categorical columns exists for train data\")\n",
    "\n",
    "        status = self.categorical_exits(test_data)\n",
    "        if status:\n",
    "            print(\"the categorical columns exists for test data\")\n",
    "\n",
    "        report = self.drift(train_data, test_data)\n",
    "        return report    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "the number of expected columns is not equal to no. of required columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m config \u001b[38;5;241m=\u001b[39m DataValidationConfig(p)\n\u001b[0;32m      3\u001b[0m data_va \u001b[38;5;241m=\u001b[39m DataValidation(config)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mdata_va\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_data_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[41], line 77\u001b[0m, in \u001b[0;36mDataValidation.initiate_data_validation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     74\u001b[0m train_data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     75\u001b[0m test_data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 77\u001b[0m status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumerical_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status:\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe numerical columns exists for train data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[41], line 28\u001b[0m, in \u001b[0;36mDataValidation.numerical_exists\u001b[1;34m(self, df)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe column \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumeric_columns[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not found in the dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:              \n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe number of expected columns is not equal to no. of required columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: the number of expected columns is not equal to no. of required columns"
     ]
    }
   ],
   "source": [
    "p = TrainingPipeline()\n",
    "config = DataValidationConfig(p)\n",
    "data_va = DataValidation(config)\n",
    "data_va.initiate_data_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
